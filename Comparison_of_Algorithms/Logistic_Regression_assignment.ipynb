{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Logistic_Regression_assignment.ipynb","provenance":[{"file_id":"https://github.com/05kartikgarg/ML_Lab_CS181104/blob/main/Logistic_Regression_using_sklearn_.ipynb","timestamp":1617206043415}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"MxWyu9cAEO68"},"source":["def normalize(X): \n","     \n","    #function to normalize feature matrix, X \n","    \n","    mins = np.min(X, axis = 0) \n","    maxs = np.max(X, axis = 0) \n","    rng = maxs - mins \n","    norm_X = 1 - ((maxs - X)/rng) \n","    return norm_X "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bt6bD98QDwXG","executionInfo":{"status":"ok","timestamp":1617205837209,"user_tz":-330,"elapsed":2466,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"74976704-9b99-4897-e7a7-30e0a0135230"},"source":["from sklearn import datasets, linear_model, metrics\n","import csv \n","import numpy as np \n","import matplotlib.pyplot as plt \n","import pandas as pd \n","dataset = pd.read_csv('/content/drive/MyDrive/gender_classification_v7.csv')  \n","dataset=np.array(dataset) \n","X = normalize(dataset[:, :-1]) \n","    \n","      \n","# stacking columns wth all ones in feature matrix \n","X = np.hstack((np.matrix(np.ones(X.shape[0])).T, X))\n","print('\\n')\n","print(X)\n","\n","# response vector \n","y = dataset[:, -1] \n","# splitting X and y into training and testing sets\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,\n","                                                    random_state=1)\n"," \n","# create logistic regression object\n","reg = linear_model.LogisticRegression()\n"," \n","# train the model using the training sets\n","reg.fit(X_train, y_train)\n","\n","# making predictions on the testing set\n","y_pred = reg.predict(X_test)\n"," \n","# comparing actual response values (y_test) with predicted response values (y_pred)\n","print(\"Logistic Regression model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","[[1.0 1.0 0.09756097560975618 ... 0.0 1.0 1.0]\n"," [1.0 0.0 0.6341463414634145 ... 0.0 1.0 0.0]\n"," [1.0 0.0 0.09756097560975618 ... 1.0 1.0 1.0]\n"," ...\n"," [1.0 1.0 0.36585365853658536 ... 0.0 0.0 0.0]\n"," [1.0 1.0 0.43902439024390216 ... 0.0 0.0 0.0]\n"," [1.0 1.0 0.9756097560975611 ... 1.0 1.0 1.0]]\n","Logistic Regression model accuracy(in %): 96.95152423788106\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M9QdqogrEVjh","executionInfo":{"status":"ok","timestamp":1617205842586,"user_tz":-330,"elapsed":1287,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"834e666f-99f4-475b-d1d5-4960370ee8ff"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H6LLNfOeDwKy","executionInfo":{"status":"ok","timestamp":1617205845306,"user_tz":-330,"elapsed":1460,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"917544b9-32a6-4b93-e9e6-fef5f5332c10"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix,accuracy_score\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n","logmodel = LogisticRegression()\n","logmodel.fit(x_train, y_train)\n"," \n","predictions = logmodel.predict(x_test)\n","print(classification_report(y_test, predictions))\n","print(confusion_matrix(y_test, predictions))\n","print(accuracy_score(y_test, predictions))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","      Female       0.97      0.97      0.97       821\n","        Male       0.97      0.97      0.97       830\n","\n","    accuracy                           0.97      1651\n","   macro avg       0.97      0.97      0.97      1651\n","weighted avg       0.97      0.97      0.97      1651\n","\n","[[795  26]\n"," [ 24 806]]\n","0.9697153240460327\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IZQJdiKHLfdw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617205851535,"user_tz":-330,"elapsed":1275,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"9915fc62-617a-4717-d877-086b154237c0"},"source":["from sklearn import datasets, linear_model, metrics\n"," \n","# load the digit dataset\n","digits = datasets.load_digits()\n"," \n","# defining feature matrix(X) and response vector(y)\n","X = digits.data\n","y = digits.target\n","\n","# splitting X and y into training and testing sets\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,\n","                                                    random_state=1)\n"," \n","# create logistic regression object\n","reg = linear_model.LogisticRegression()\n"," \n","# train the model using the training sets\n","reg.fit(X_train, y_train)\n","\n","# making predictions on the testing set\n","y_pred = reg.predict(X_test)\n"," \n","# comparing actual response values (y_test) with predicted response values (y_pred)\n","print(\"Logistic Regression model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Logistic Regression model accuracy(in %): 96.52294853963839\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s6q4fhgs8uON","executionInfo":{"status":"ok","timestamp":1617205863090,"user_tz":-330,"elapsed":1630,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"f498749c-8f8c-45bc-ea88-546006e45449"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix,accuracy_score\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n","logmodel = LogisticRegression()\n","logmodel.fit(x_train, y_train)\n"," \n","predictions = logmodel.predict(x_test)\n","print(classification_report(y_test, predictions))\n","print(confusion_matrix(y_test, predictions))\n","print(accuracy_score(y_test, predictions))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        63\n","           1       0.95      0.95      0.95        59\n","           2       0.98      1.00      0.99        55\n","           3       0.97      0.96      0.96        68\n","           4       0.97      0.98      0.98        66\n","           5       0.96      0.90      0.93        52\n","           6       1.00      1.00      1.00        54\n","           7       0.98      0.95      0.97        62\n","           8       0.89      0.98      0.93        51\n","           9       0.95      0.94      0.94        64\n","\n","    accuracy                           0.97       594\n","   macro avg       0.97      0.97      0.97       594\n","weighted avg       0.97      0.97      0.97       594\n","\n","[[63  0  0  0  0  0  0  0  0  0]\n"," [ 0 56  0  0  1  0  0  0  2  0]\n"," [ 0  0 55  0  0  0  0  0  0  0]\n"," [ 0  0  0 65  0  0  0  1  2  0]\n"," [ 0  1  0  0 65  0  0  0  0  0]\n"," [ 0  1  1  1  0 47  0  0  0  2]\n"," [ 0  0  0  0  0  0 54  0  0  0]\n"," [ 0  0  0  1  1  0  0 59  0  1]\n"," [ 0  0  0  0  0  1  0  0 50  0]\n"," [ 0  1  0  0  0  1  0  0  2 60]]\n","0.9663299663299664\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"}]}]}